<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Super-Resolution for medical imaging | Hendrik&#39;s Portfolio</title>
<meta name="keywords" content="">
<meta name="description" content="By leveraging diffusion models, low-resolution MRI scans are upgraded to high-resolution images. The model is trained on image pairs, enabling it to learn noise reduction and generate clearer, more detailed MRI scans.
Code : https://github.com/chichonnade/MRI-Super-Resolution/tree/main Demo : Low Resolution 1.5T to High Resolution 3T MRI Overview Latest diffusion models have shown promising results in super-resolution tasks. This project aims to leverage these models to enhance the resolution of MRI images.">
<meta name="author" content="">
<link rel="canonical" href="https://chichonnade.github.io/posts/mri-super-resolution/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.e89167da98a125ec0befca7a575524200f207fdb2add592b38321a7ca772106c.css" integrity="sha256-6JFn2pihJewL78p6V1UkIA8gf9sq3VkrODIafKdyEGw=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://chichonnade.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://chichonnade.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://chichonnade.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://chichonnade.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://chichonnade.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://chichonnade.github.io/posts/mri-super-resolution/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:title" content="Super-Resolution for medical imaging" />
<meta property="og:description" content="By leveraging diffusion models, low-resolution MRI scans are upgraded to high-resolution images. The model is trained on image pairs, enabling it to learn noise reduction and generate clearer, more detailed MRI scans.
Code : https://github.com/chichonnade/MRI-Super-Resolution/tree/main Demo : Low Resolution 1.5T to High Resolution 3T MRI Overview Latest diffusion models have shown promising results in super-resolution tasks. This project aims to leverage these models to enhance the resolution of MRI images." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chichonnade.github.io/posts/mri-super-resolution/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-08-21T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-08-21T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Super-Resolution for medical imaging"/>
<meta name="twitter:description" content="By leveraging diffusion models, low-resolution MRI scans are upgraded to high-resolution images. The model is trained on image pairs, enabling it to learn noise reduction and generate clearer, more detailed MRI scans.
Code : https://github.com/chichonnade/MRI-Super-Resolution/tree/main Demo : Low Resolution 1.5T to High Resolution 3T MRI Overview Latest diffusion models have shown promising results in super-resolution tasks. This project aims to leverage these models to enhance the resolution of MRI images."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://chichonnade.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Super-Resolution for medical imaging",
      "item": "https://chichonnade.github.io/posts/mri-super-resolution/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Super-Resolution for medical imaging",
  "name": "Super-Resolution for medical imaging",
  "description": "By leveraging diffusion models, low-resolution MRI scans are upgraded to high-resolution images. The model is trained on image pairs, enabling it to learn noise reduction and generate clearer, more detailed MRI scans.\nCode : https://github.com/chichonnade/MRI-Super-Resolution/tree/main Demo : Low Resolution 1.5T to High Resolution 3T MRI Overview Latest diffusion models have shown promising results in super-resolution tasks. This project aims to leverage these models to enhance the resolution of MRI images.",
  "keywords": [
    
  ],
  "articleBody": " By leveraging diffusion models, low-resolution MRI scans are upgraded to high-resolution images. The model is trained on image pairs, enabling it to learn noise reduction and generate clearer, more detailed MRI scans.\nCode : https://github.com/chichonnade/MRI-Super-Resolution/tree/main Demo : Low Resolution 1.5T to High Resolution 3T MRI Overview Latest diffusion models have shown promising results in super-resolution tasks. This project aims to leverage these models to enhance the resolution of MRI images. It involves training a diffusion model on HR / LR MRI pairs to learn the noise distribution and generate high-resolution images from low-resolution inputs. Using a cascade of these models, we can achieve significant improvements in image quality.\nForward noise process Using a cosine noise schedule, we can gradually add noise to the input image, allowing the model to learn the noise distribution and generate high-resolution images. The noise variance is increased over 1000 steps with a maximum variance of 0.3 at the final step to prevent adding out-of-bound noise values.\nHere are the formulas used:\nCosine Schedule for Alphas: $$ \\alpha_t = \\cos^2\\left(\\frac{\\pi t}{2T}\\right) $$ Cumulative Product of Alphas: $$\\bar{\\alpha_{t}} = \\prod_{i=1}^{t}\\alpha_i$$ Forward Noise Process: $$ q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, 0.3(1 - \\bar{\\alpha}_t) I) $$ \\( x_t \\) can be sampled as: \\[ x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{(1 - \\bar{\\alpha}_t)} \\varepsilon_{t}, \\text{ where } \\varepsilon_{t} \\sim \\mathcal{N}(0, \\mathbf{0.3I}) \\]Where:\n\\( \\alpha_t \\) represents the amount of signal retained at time step \\( t \\). \\( \\bar{\\alpha}_t \\) is the cumulative product of the alpha values up to time step \\( t \\). \\( x_t \\) is the noisy image at step \\( t \\). \\( x_0 \\) is the original image. \\( q(x_t \\mid x_0) \\) represents the probability distribution of the noisy image given the original image. LR/HR pairs We use the Human Connectome Project (HCP) dataset, which contains both 1.5T and 3T MRI scans. The LR images are generated by downsampling the HR images using the spline interpolation method. Then we train the diffusion model on these LR/HR pairs to learn the noise distribution and generate high-resolution images.\nReverse process using a 3D-Unet Our model is based on the original DDPM architecture with 3D convolutions to handle the 3D MRI data. The model consists of a series of diffusion steps, each with a series of 3D convolutions, normalization layers, and attention blocks.\nReverse Noise Schedule for Betas: $$ \\beta_t = \\frac{1 - \\alpha_{t+1}}{1 - \\bar{\\alpha}_{t+1}} $$ Variance of the Reverse Process: $$ \\sigma_t^2 = \\frac{1 - \\bar{\\alpha}_t}{1 - \\bar{\\alpha}_{t+1}} \\beta_t $$ Reverse Process Sampling: $$ p(x_{t-1} \\mid x_t, x_0) = \\mathcal{N}(x_{t-1}; \\mu_t(x_t, x_0), \\sigma_t^2 I) $$ Mean of the Reverse Process: $$ \\mu_t(x_t, x_0) = \\frac{\\sqrt{\\bar{\\alpha}_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} x_0 + \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} x_t $$ Where:\n\\( \\beta_t \\) represents the noise variance for the reverse process at time step \\( t \\). \\( \\sigma_t^2 \\) is the variance of the reverse process, which determines how much noise is reduced at each reverse step. \\( x_t \\) is the noisy image at step \\( t \\). \\( x_{t-1} \\) is the denoised image at the previous step \\( t-1 \\). \\( \\mu_t(x_t, x_0) \\) is the mean of the reverse process, guiding the denoising from \\( x_t \\) to \\( x_{t-1} \\). \\( p(x_{t-1} \\mid x_t, x_0) \\) represents the probability distribution of the denoised image at step \\( t-1 \\) given the noisy image at step \\( t \\) and the original image \\( x_0 \\). Updates Currently assessing the performance of two reverse process models. A 3D-Unet for best performance and a combination of 3 2D-Unets to reduce training cost.\nCredits: This project was conducted in collaboration with GENCI who provided the computational ressources. Authored by Hendrik Chiche, Ludovic Corcos and Logan Rouge. ",
  "wordCount" : "625",
  "inLanguage": "en",
  "datePublished": "2024-08-21T00:00:00Z",
  "dateModified": "2024-08-21T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://chichonnade.github.io/posts/mri-super-resolution/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Hendrik's Portfolio",
    "logo": {
      "@type": "ImageObject",
      "url": "https://chichonnade.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://chichonnade.github.io/" accesskey="h" title="Hendrik&#39;s Portfolio (Alt + H)">Hendrik&#39;s Portfolio</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Super-Resolution for medical imaging
    </h1>
    <div class="post-meta"><span title='2024-08-21 00:00:00 +0000 UTC'>August 21, 2024</span>

</div>
  </header> 
  <div class="post-content">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<p>By leveraging diffusion models, low-resolution MRI scans are upgraded to high-resolution images. The model is trained on image pairs, enabling it to learn noise reduction and generate clearer, more detailed MRI scans.</p>
<h4 id="code--httpsgithubcomchichonnademri-super-resolutiontreemain">Code : <a href="https://github.com/chichonnade/MRI-Super-Resolution/tree/main">https://github.com/chichonnade/MRI-Super-Resolution/tree/main</a><a hidden class="anchor" aria-hidden="true" href="#code--httpsgithubcomchichonnademri-super-resolutiontreemain">#</a></h4>
<h2 id="demo--low-resolution-15t-to-high-resolution-3t-mri">Demo : Low Resolution 1.5T to High Resolution 3T MRI<a hidden class="anchor" aria-hidden="true" href="#demo--low-resolution-15t-to-high-resolution-3t-mri">#</a></h2>
<div style="text-align: center">
    
   <img src="assets/mri_slice_LR.gif" alt="Low Resolution MRI" width="900" style="display: block; margin-left: auto; margin-right: auto;" />
   <img src="assets/mri_slice_HR.gif" alt="High Resolution MRI" width="900" style="display: block; margin-left: auto; margin-right: auto;" />

</div>
<h2 id="overview">Overview<a hidden class="anchor" aria-hidden="true" href="#overview">#</a></h2>
<p>Latest diffusion models have shown promising results in super-resolution tasks. This project aims to leverage these models to enhance the resolution of MRI images. It involves training a diffusion model on HR / LR MRI pairs to learn the noise distribution and generate high-resolution images from low-resolution inputs. Using a cascade of these models, we can achieve significant improvements in image quality.</p>
<h2 id="forward-noise-process">Forward noise process<a hidden class="anchor" aria-hidden="true" href="#forward-noise-process">#</a></h2>
<p><img src="assets/cosine_noise_scheduler.png" alt="High Resolution MRI" width="900" style="display: block; margin-left: auto; margin-right: auto;" />
Using a cosine noise schedule, we can gradually add noise to the input image, allowing the model to learn the noise distribution and generate high-resolution images. The noise variance is increased over 1000 steps with a maximum variance of 0.3 at the final step to prevent adding out-of-bound noise values.</p>
<p>Here are the formulas used:</p>
<ol>
<li>
<p><strong>Cosine Schedule for Alphas</strong>:
</p>
$$ \alpha_t = \cos^2\left(\frac{\pi t}{2T}\right) $$</li>
<li>
<p><strong>Cumulative Product of Alphas</strong>:
</p>
$$\bar{\alpha_{t}} = \prod_{i=1}^{t}\alpha_i$$</li>
<li>
<p><strong>Forward Noise Process</strong>:
</p>
$$ q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, 0.3(1 - \bar{\alpha}_t) I) $$</li>
</ol>
<p>\( x_t \) can be sampled as: </p>
\[ x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{(1 - \bar{\alpha}_t)} \varepsilon_{t}, \text{ where } \varepsilon_{t} \sim \mathcal{N}(0, \mathbf{0.3I}) \]<p>Where:</p>
<ul>
<li>\( \alpha_t \) represents the amount of signal retained at time step \( t \).</li>
<li>\( \bar{\alpha}_t \) is the cumulative product of the alpha values up to time step \( t \).</li>
<li>\( x_t \) is the noisy image at step \( t \).</li>
<li>\( x_0 \) is the original image.</li>
<li>\( q(x_t \mid x_0) \) represents the probability distribution of the noisy image given the original image.</li>
</ul>
<h2 id="lrhr-pairs">LR/HR pairs<a hidden class="anchor" aria-hidden="true" href="#lrhr-pairs">#</a></h2>
<p>We use the Human Connectome Project (HCP) dataset, which contains both 1.5T and 3T MRI scans. The LR images are generated by downsampling the HR images using the spline interpolation method. Then we train the diffusion model on these LR/HR pairs to learn the noise distribution and generate high-resolution images.</p>
<h2 id="reverse-process-using-a-3d-unet">Reverse process using a 3D-Unet<a hidden class="anchor" aria-hidden="true" href="#reverse-process-using-a-3d-unet">#</a></h2>
<div style="text-align: center">
    
   <img src="assets/3DUnetSuperRes.png" alt="Low Resolution MRI" width="600" style="display: block; margin-left: auto; margin-right: auto;" />

</div>
<p>Our model is based on the original DDPM architecture with 3D convolutions to handle the 3D MRI data. The model consists of a series of diffusion steps, each with a series of 3D convolutions, normalization layers, and attention blocks.</p>
<ol>
<li>
<p><strong>Reverse Noise Schedule for Betas</strong>:
</p>
$$ \beta_t = \frac{1 - \alpha_{t+1}}{1 - \bar{\alpha}_{t+1}} $$</li>
<li>
<p><strong>Variance of the Reverse Process</strong>:
</p>
$$ \sigma_t^2 = \frac{1 - \bar{\alpha}_t}{1 - \bar{\alpha}_{t+1}} \beta_t $$</li>
<li>
<p><strong>Reverse Process Sampling</strong>:
</p>
$$ p(x_{t-1} \mid x_t, x_0) = \mathcal{N}(x_{t-1}; \mu_t(x_t, x_0), \sigma_t^2 I) $$</li>
<li>
<p><strong>Mean of the Reverse Process</strong>:
</p>
$$ \mu_t(x_t, x_0) = \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} x_t $$</li>
</ol>
<p>Where:</p>
<ul>
<li>\( \beta_t \) represents the noise variance for the reverse process at time step \( t \).</li>
<li>\( \sigma_t^2 \) is the variance of the reverse process, which determines how much noise is reduced at each reverse step.</li>
<li>\( x_t \) is the noisy image at step \( t \).</li>
<li>\( x_{t-1} \) is the denoised image at the previous step \( t-1 \).</li>
<li>\( \mu_t(x_t, x_0) \) is the mean of the reverse process, guiding the denoising from \( x_t \) to \( x_{t-1} \).</li>
<li>\( p(x_{t-1} \mid x_t, x_0) \) represents the probability distribution of the denoised image at step \( t-1 \) given the noisy image at step \( t \) and the original image \( x_0 \).</li>
</ul>
<h2 id="updates">Updates<a hidden class="anchor" aria-hidden="true" href="#updates">#</a></h2>
<p>Currently assessing the performance of two reverse process models. A 3D-Unet for best performance and a combination of 3 2D-Unets to reduce training cost.</p>
<p><br><br>
<span style="color: grey;"> Credits:</span> <br>
<span style="color: grey;">This project was conducted in collaboration with <a href="https://www.genci.fr/en">GENCI</a> who provided the computational ressources. Authored by Hendrik Chiche, Ludovic Corcos and Logan Rouge.
</span></p>
<img src="assets/genci.png" alt="" width="300" style="display: block; margin-left: auto; margin-right: auto;" />


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://chichonnade.github.io/">Hendrik&#39;s Portfolio</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
